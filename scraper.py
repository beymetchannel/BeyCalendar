import json
import re
import os
from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup
from datetime import datetime

# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆURL
URL = "https://beyblade.takaratomy.co.jp/beyblade-x/event/schedule.html#schedule"

def get_color_class(event_type):
    """ã‚¤ãƒ™ãƒ³ãƒˆç¨®åˆ¥ã«åŸºã¥ã„ã¦CSSã‚¯ãƒ©ã‚¹ã‚’æ±ºå®šï¼ˆJSãƒ­ã‚¸ãƒƒã‚¯ã¨åŒæœŸï¼‰"""
    if "G3å¤§ä¼šï¼ˆãƒ¬ã‚®ãƒ¥ãƒ©ãƒ¼" in event_type or "ãƒ¬ã‚®ãƒ¥ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹" in event_type:
        return 'G3(R)'
    elif "G3å¤§ä¼šï¼ˆã‚ªãƒ¼ãƒ—ãƒ³" in event_type or "ã‚ªãƒ¼ãƒ—ãƒ³ã‚¯ãƒ©ã‚¹" in event_type:
        return 'G3(O)'
    elif "S1ã‚¤ãƒ™ãƒ³ãƒˆ" in event_type:
        return 'S1'
    elif "ã‚¢ãƒ³ãƒã‚µãƒ€ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆ" in event_type:
        return 'Amb'
    elif "G2å¤§ä¼š" in event_type:
        return 'G2'
    elif "G1å¤§ä¼š" in event_type:
        return 'G1'
    else:
        return 'ãã®ä»–'

def scrape_beyblade_events_dynamic():
    """Playwrightã‚’ä½¿ç”¨ã—ã¦å‹•çš„ã«èª­ã¿è¾¼ã¾ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹"""
    events_data = []
    
    with sync_playwright() as p:
        try:
            browser = p.chromium.launch()
            page = browser.new_page()
            
            print(f"Navigating to {URL}...")
            
            # ğŸ’¡ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’60ç§’ã«å»¶é•·ã—ã€å¾…æ©Ÿæ¡ä»¶ã‚’ç·©å’Œ
            page.goto(URL, wait_until="domcontentloaded", timeout=60000) 
            
            # ğŸ’¡ æœ€ã‚‚åºƒã„ç¯„å›²ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ–ãƒ­ãƒƒã‚¯ã®å‡ºç¾ã‚’å¾…æ©Ÿã™ã‚‹
            # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å…¨ä½“ã‚’å›²ã‚€ã‚³ãƒ³ãƒ†ãƒŠè¦ç´ ã‚’æ¢ã™
            print("Waiting for schedule container...")
            page.wait_for_selector('div.schedule-container', timeout=30000) 
            
            # å®Œå…¨ã«ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸHTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
            content = page.content()
            browser.close()

            # Beautiful Soupã§HTMLã‚’è§£æ
            soup = BeautifulSoup(content, 'html.parser')
            
            # ã‚¤ãƒ™ãƒ³ãƒˆè¦ç´ ã‚’å…¨ã¦å–å¾—
            event_elements = soup.find_all('div', class_='event-list-item')
            print(f"DEBUG: Found {len(event_elements)} raw event elements.")
            
            if not event_elements:
                print("Warning: No event elements found on the page. Returning empty list.")
                return []
            
            for item in event_elements:
                try:
                    date_time_str = item.find('p', class_='date-time').text.strip()
                    date_match = re.search(r'(\d{4}å¹´\s*\d{1,2}æœˆ\d{1,2}æ—¥)', date_time_str)
                    time_match = re.search(r'(\d{1,2}ï¼š\d{2})', date_time_str)
                    
                    date_str = date_match.group(1).strip() if date_match else "æ—¥ä»˜ä¸æ˜"
                    time_str = time_match.group(1).strip() if time_match else "æ™‚é–“ä¸æ˜"

                    event_type = item.find('p', class_='event-name').text.strip()
                    name_location = item.find('p', class_='name-location').text.strip()
                    address = item.find('p', class_='address').text.strip()
                    details = ' '.join([p.text.strip() for p in item.find_all('p', class_='text-style-01')]).replace('\n', ' ')

                    events_data.append({
                        "date": date_str,
                        "time": time_str,
                        "type": event_type,
                        "name": name_location,
                        "location": name_location,
                        "address": address,
                        "details": details,
                        "color_label": get_color_class(event_type) 
                    })
                    
                except AttributeError as e:
                    print(f"Skipping event due to missing tag: {e}")

            print(f"DEBUG: Successfully processed {len(events_data)} structured events.")
            return events_data

        except Exception as e:
            # Playwrightã®ã‚¨ãƒ©ãƒ¼ã‚„ãã®ä»–ã®äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ã‚’ã“ã“ã§æ•æ‰
            print(f"Playwright execution failed: {e}")
            return []

def save_data(data):
    """ãƒ‡ãƒ¼ã‚¿ã‚’data/events.jsonã«ä¿å­˜ã™ã‚‹"""
    os.makedirs('data', exist_ok=True)
    with open('data/events.json', 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)
    print(f"Successfully saved {len(data)} events to data/events.json")


if __name__ == "__main__":
    # ğŸš¨ NameErrorä¿®æ­£: æ­£ã—ã„é–¢æ•°åã‚’å‘¼ã³å‡ºã™
    extracted_data = scrape_beyblade_events_dynamic() 
    if extracted_data:
        save_data(extracted_data)
